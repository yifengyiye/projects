# loading your dataset:
from sklearn import *
digits = datasets.load_digits()
import pandas as pd
digits2 = pd.read_csv("http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra",header=None)
# print digits



# explore your data
    #gathering basic information on your data
'''
print digits.keys()
print digits2.keys()
print digits.images
print '------------------------------------------------------'
print digits.data
print digits.DESCR
print digits.target_names  
print digits.target
print digits2.head()
print digits2.tail()
print digits.data.shape 
print digits.images.shape 
print digits.target.shape 
import numpy as np 
print len(np.unique(digits.target))
'''


#visualize your data images with matplotlib 
import matplotlib.pyplot as plt 
'''
fig = plt.figure(figsize=(8,8))
fig.subplots_adjust(left=0,right=1,bottom=0,top=1,hspace=0.5,wspace=0.5)
for i in range(64):
	ax = fig.add_subplot(8,8,i+1,xticks=[],yticks=[])
	ax.imshow(digits.images[i],cmap=plt.cm.binary,interpolation='nearest')
	ax.text(0,7,str(digits.target[i]))
plt.show()
'''
'''
images_and_target = list(zip(digits.images,digits.target))
for index,(image,label) in enumerate(images_and_target[:10]):
	plt.subplot(2,5,index+1)
	plt.axis('off')
	plt.imshow(image,cmap=plt.cm.gray_r,interpolation='nearest')
	plt.title('Training:'+str(label))
plt.show()
'''


#visualizing your data:Principal Component Ananlysis(PCA)
'''
randomized_pca = RandomizedPCA(n_component=2)
reduced_data_rpca = randomized_pca.fit_transform(digits.data)
pca = PCA(n_component=2)
reduced_data_pca = pca.fit_transform(digits.data)
print reduced_data_pca.shape 
print reduced_data_rpca
print reduced_data_pca

colors = ['black','blue','purple','yellow','white','red','lime','cyan','orange','gray']
for i in range(len(colors)):
	x = reduced_data_rpca[:,0][digits.target == i]
	y = reduced_data_rpca[:,1][digits.target == i]
	plt.scatter(x,y,c=colors[i])
plt.legend(digits.target_names,bbox_to_anchor=(1.05,1),loc=2,borderaxspad=0.)
plt.show()
'''
#where to go now


#preprocessing your data


#data normalization
from sklearn.preprocessing import scale 
data = scale(digits.data)

#splitting your data into training and test sets
import numpy as np 

from sklearn.cross_validation import train_test_split 
x_train,x_test,y_train,y_test,images_train,images_test = train_test_split(digits.data,digits.target,digits.images,test_size=0.25,random_state=42)
print x_train.shape
print x_test.shape
print y_train.shape
print y_test.shape
print images_train.shape
print images_test.shape
print len(y_train)
print len(np.unique(y_train))


#clustering the digits data

from sklearn import cluster 
clf = cluster.KMeans(init='k-means++',n_clusters=10,random_state=42)
clf.fit(x_train)
'''
import matplotlib.pyplot as plt 
fig = plt.figure(figsize=(8,3))
fig.suptitle('cluster center images',fontsize=14,fontweight='bold')
for i in range(10):
	ax = fig.add_subplot(2,5,i+1)
	ax.imshow(clf.cluster_centers_[i].reshape((8,8)),cmap=plt.cm.binary)
	plt.axis('off')
plt.show()
'''
y_pred = clf.predict(x_test)
print y_pred[:100]
print y_test[:100]
print zip(y_pred[:50]-y_test[:50])
print clf.cluster_centers_.shape
'''
	#visualize the predicted labels
from sklearn.manifold import Isomap 
x_iso = Isomap(n_neighbors=10).fit_transform(x_train)
clusters = clf.fit_predict(x_train)
fig,ax = plt.subplots(1,2,figsize = (10,5))
fig.suptitle('isomap:predicted versus training labels',fontsize = 14,fontweight='bold')
fig.subplots_adjust(top=0.85)
ax[0].scatter(x_iso[:,0],x_iso[:,1],c=clusters)
ax[0].set_title('predicted training labels')
ax[1].scatter(x_iso[:,0],x_iso[:,1],c=y_train)
ax[1].set_title('actual training labels')
plt.show()

from sklearn.decomposition import PCA
x_pca = PCA(n_components=2).fit_transform(x_train)
clusters = clf.fit_predict(x_train)
fig,ax = plt.subplots(1,2,figsize=(10,5))
fig.suptitle('pca:xpredicted versus training labels',fontsize=14,fontweight='bold')
fig.subplots_adjust(top=0.85)
ax[0].scatter(x_pca[:,0],x_pca[:,1],c=clusters)
ax[0].set_title('predicted training labels')
ax[1].scatter(x_pca[:,0],x_pca[:,1],c=y_train)
ax[1].set_title('actual training labels')
plt.show()
'''

#evaluation of your clustering model
from sklearn import metrics 
print metrics.confusion_matrix(y_test,y_pred)

from sklearn.metrics import homogeneity_score,completeness_score,v_measure_score,adjusted_rand_score,adjusted_mutual_info_score,silhouette_score
print "% 9s" %'intertia homo compl v-meas ARI AMI silhouette'
print "%i %.3f %.3f %.3f %.3f %.3f %.3f" %(clf.inertia_,
	homogeneity_score(y_test,y_pred),
	completeness_score(y_test,y_pred),
	v_measure_score(y_test,y_pred),
	adjusted_rand_score(y_test,y_pred),
	adjusted_mutual_info_score(y_test,y_pred),
	silhouette_score(x_test,y_pred,metric='euclidean'))


# trying out another model:support vector machines 
from sklearn.cross_validation import train_test_split
x_train, x_test, y_train, y_test, images_train, images_test = train_test_split(digits.data,digits.target,digits.images,test_size=0.25,random_state=42)
from sklearn import svm 
svc_model = svm.SVC(gamma=0.001,C=100.,kernel='linear')
svc_model.fit(x_train,y_train)

x_train, x_test, y_train, y_test = train_test_split(digits.data,digits.target,test_size=0.5, random_state=0)
from sklearn.grid_search import GridSearchCV 
parameter_condidates = [
	{"C":[1,10,100,1000],"kernel":['linear']},
	{"C":[1,10,100,1000],"gamma":[0.001,0.0001],"kernel":['rbf']}]
clf = GridSearchCV(estimator=svm.SVC(),param_grid=parameter_condidates,n_jobs=-1)
clf.fit(x_train,y_train)
print 'best score for training data:',clf.best_score_
print 'best `C`:',clf.best_estimator_.C 
print 'best kernel:',clf.best_estimator_.kernel
print 'best gamma:',clf.best_estimator_.gamma
clf.score(x_test,y_test)
svm.SVC(C=10,kernel='rbf',gamma=0.001).fit(x_train,y_train).score(x_test,y_test)
print svc_model.predict(x_test)
print y_test 

import matplotlib.pyplot as plt 
predicted = svc_model.predict(x_test)
images_and_predictions = list(zip(images_test,predicted))
for index ,(image,prediction) in enumerate(images_and_predictions[:4]):
	plt.subplot(1,4,index+1)
	plt.axis('off')
	plt.imshow(image,cmap=plt.cm.gray_r,interpolation='nearest')
	plt.title('predicted:'+str(prediction))
plt.show()

from sklearn import metrics 
print metrics.classification_report(y_test,predicted)
print metrics.confusion_matrix(y_test,predicted)

from sklearn.manifold import Isomap 
x_iso = Isomap(n_neighbors=10).fit_transform(x_train)
predicted = svc_model.predict(x_train)
fig,ax = plt.subplots(1,2,figsize=(8,4))
fig.subplots_adjust(top=0.85)
ax[0].scatter(x_iso[:,0],x_iso[:,1],c=predicted)
ax[0].set_title('predicted labels')
ax[1].scatter(x_iso[:,0],x_iso[:,1],c=y_train)
ax[1].set_title('actual labels')
fig.suptitle('predicted versus actual labels',fontsize=14,fontweight='bold')
plt.show()


#digit recognition in natural images 
